---
title: "Simulating Data"
author: "Kristian Severin"
date: "2023-05-12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# loading packages
pacman::p_load(  
  tidyverse,
  brms,
  cmdstanr,
  patchwork,
  future, 
  purrr, 
  furrr
  )

source("SimpleBayes_f.R")  # get self-written simplebayes function from source
source("SimulatingData_f.R")  # get self-written data-simulating function from source
source("sim_d_and_fit_f.R")  # get self-written function that fits different priors to the model 
```

Simulating data

```{r}
# set up experimental conditions
nskiers <- 10
ntrials <- 100
bias <- .8
accumulatedAviCond <- c(0,1,2,3,4,5,6)
accumulatedTerrainCond <- c(0,1,2,3,4)

# use self-written function to get simulated data
sim_df <- simulating_skiing(nskiers,ntrials, bias)

```

```{r}
# get sources within scope for working with log-odds (i.e., avoid 0 and 1)
sim_df$Source1 <- ifelse(sim_df$Source1 == 0, 0.01, 
                  ifelse(sim_df$Source1 == 1, 0.99, sim_df$Source1))  # i.e., hardcode 0 to be 0.01 and 1 to be 0.99

sim_df$Source2 <- ifelse(sim_df$Source2 == 0, 0.01, 
                  ifelse(sim_df$Source2 == 1, 0.99, sim_df$Source2))  # i.e., hardcode 0 to be 0.01 and 1 to be 0.99
```

```{r}
# prior sensitivty check data
dataSimpleBayesSens <- list(
  N = nrow(sim_df),
  outcome = sim_df$outcome,
  Source1 = sim_df$Source1,
  Source2 = sim_df$Source2
)

# feed R the stan model 
file <- file.path("simplebayes.stan")  # for the purposes a one-level model is fine
mod_simpleBayes_sens <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
# create samples from the model
samples_simple_sens <- mod_simpleBayes_sens$sample(
  data = dataSimpleBayesSens,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1500,
  iter_sampling = 3000,
  refresh = 500
)

# get the resulting data frame
draws_df_sens <- as_draws_df(samples_simple_sens$draws())
```

```{r}
# prior sensitivity plots
ggplot(draws_df_sens) +
  geom_density(aes(inv_logit_scaled(bias)), fill = "blue", alpha = 0.3) +  # get bias on log-odds
  geom_density(aes(bias_prior), fill = "red", alpha = 0.3) +
  geom_vline(xintercept = 0, size = 2) +
  xlab("Bias") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df_sens) +
  geom_histogram(aes(`prior_preds`), color = "purple", fill = "#CC66FF", alpha = 0.2) +
  geom_histogram(aes(`prior_preds5`), color = "yellow", fill = "lightyellow", alpha = 0.2) +
  geom_histogram(aes(`prior_preds7`), color = "green", fill = "lightgreen", alpha = 0.2) +
  geom_histogram(aes(`prior_preds9`), color = "blue", fill = "lightblue", alpha = 0.2) +
  xlab("Predicted skied runs out of 1000") +
  ylab("Posterior Density") +
  theme_classic()
```


```{r}
# pivot data wider
sim_wide <- sim_df %>% 
  group_by(skier) %>% 
  subset(select = c(skier, outcome, Source1, Source2)) %>%
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = skier, values_from = c(outcome, Source1, Source2))

# Create the data
dataSimpleBayes <- list(
  N = ntrials,
  S = nskiers,
  outcome = as.matrix(sim_wide[,2:11]),
  Source1 = as.matrix(sim_wide[,12:21]),
  Source2 = as.matrix(sim_wide[,22:31])
)

# feed R the stan model
file <- file.path("simplebayesML.stan")
mod_simpleBayes <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
# create samples from the model
samples_simple <- mod_simpleBayes$sample(
  data = dataSimpleBayes,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1500,
  iter_sampling = 3000,
  refresh = 500
)

# get the resulting data frame
draws_df <- as_draws_df(samples_simple$draws())
```


```{r}
# basic evaluation
samples_simple$cmdstan_diagnose()
# diagnostics
samples_simple$summary()
samples_simple$loo()

```

```{r}
# chains mixing plot
p1 <- ggplot(draws_df, aes(.iteration, `bias[1]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p2 <- ggplot(draws_df, aes(.iteration, `bias[2]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p3 <- ggplot(draws_df, aes(.iteration, `bias[3]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p4 <- ggplot(draws_df, aes(.iteration, `bias[4]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p5 <- ggplot(draws_df, aes(.iteration, `bias[5]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p6 <- ggplot(draws_df, aes(.iteration, `bias[6]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p7 <- ggplot(draws_df, aes(.iteration, `bias[7]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p8 <- ggplot(draws_df, aes(.iteration, `bias[8]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p9 <- ggplot(draws_df, aes(.iteration, `bias[9]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p10 <- ggplot(draws_df, aes(.iteration, `bias[10]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()

p_all <- (p1 + p2) + (p3 + p4) + (p5 + 
  p6) + (p7 + p8) + (p9 + p10) + plot_layout(nrow=5, ncol = 2)

p_all

```

```{r}
p_z <- ggplot(draws_df, aes(.iteration, `bias_prior[1]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()

p_z
```


```{r}
# bias plot
ggplot(draws_df) +
  geom_density(aes(`bias_posterior[1]`), alpha = 0.6, fill = "lightblue") +
    annotate("text", colour = "lightblue", x = 0.01, y = 46, label = "Posterior Distribution Bias" , hjust = 0)+
  geom_density(aes(`bias_prior[1]`), alpha = 0.6, fill = "pink") +
    annotate("text", colour = "pink", x = 0.01, y = 43, label = "Prior Distribution Bias", hjust =0)+
  xlab("Bias")+
  ylab("Estimate Densitites")+
  theme_bw()+
  geom_vline(xintercept = sim_df$bias[1], linetype = "dashed", size = 1.5) +
    annotate("text", x = 0.01, y = 40,  label="True Bias", hjust = 0)+
  geom_rect(aes(xmin = 0, xmax = 0.3, ymin = 38, ymax = 48), 
            fill = "white", color = "black", alpha = 0)

# bias plot
ggplot(draws_df) +
  geom_density(aes(`bias_posterior[2]`), alpha = 0.6, fill = "lightblue") +
    annotate("text", colour = "lightblue", x = 0.01, y = 46, label = "Posterior Distribution Bias" , hjust = 0)+
  geom_density(aes(`bias_prior[2]`), alpha = 0.6, fill = "pink") +
    annotate("text", colour = "pink", x = 0.01, y = 43, label = "Prior Distribution Bias", hjust =0)+
  xlab("Bias")+
  ylab("Estimate Densitites")+
  theme_bw()+
  geom_vline(xintercept = sim_df$bias[1], linetype = "dashed", size = 1.5) +
    annotate("text", x = 0.01, y = 40,  label="True Bias", hjust = 0)+
  geom_rect(aes(xmin = 0, xmax = 0.3, ymin = 38, ymax = 48), 
            fill = "white", color = "black", alpha = 0)

```



```{r}
# prior predictions
ggplot(draws_df) +
  geom_histogram(aes(`prior_preds[1]`), color = "darkblue", fill = "blue", alpha = 0.3) +
  xlab("Predicted skied runs of 1000 trials") +
  ylab("Posterior Density") +
  theme_classic()

# posterior predictions 
ggplot(draws_df) +
  geom_histogram(aes(`posterior_preds[1]`), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90)+
  geom_point(x = sum(sim_df$outcome), y = 0, color = "red", shape = 17, size = 5) +  # not visible
  xlab("Predicted skied runs out of 1000 trials") +
  ylab("Posterior Density") +
  theme_classic()

ggplot(draws_df) +
  geom_histogram(aes(`prior_preds[1]`), color = "lightblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_histogram(aes(`posterior_preds[1]`), color = "darkblue", fill = "blue", alpha = 0.3, bins = 90) +
  geom_point(x = sum(sim_df$outcome), y = 0, color = "red", shape = 17, size = 5) +
  xlab("Predicted skied runs out of 1000 trials") +
  ylab("Posterior Density") +
  theme_classic()
```
maybe look at this later

```{r}
# A plot of the proportion of right hand choices for the random agents
p1 <- ggplot(sim_df, aes(trial, skier, group = outcome, color = outcome)) + 
  geom_line(alpha = 0.5) + 
  geom_hline(yintercept = 0.5, linetype = "dashed") + 
  ylim(0,1) + 
  theme_classic() 
p1
```




```{r}
# feed R the stan model with priors
file <- file.path("sbPriors.stan")
mod <- cmdstan_model(file, 
                     cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))

# use all cores on the computer
plan(multisession, workers = 4)

# calling function self-written function that simulates data and fits it by sequences of different priors
recovery_df <- future_pmap_dfr(priors, sim_d_and_fit, .options = furrr_options(seed = TRUE))

```

```{r}
# recovery
ggplot(recovery_df, aes(prior_mean, bias_posterior1)) +
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = 0.8, color = "red") +
  geom_smooth() +
  facet_wrap(.~prior_sd) +
  theme_classic()

ggplot(recovery_df, aes(prior_mean, bias_posterior2)) +
  geom_point(alpha = 0.1) +
  geom_hline(yintercept = 0.8, color = "red") +
  geom_smooth() +
  facet_wrap(.~prior_sd) +
  theme_classic()

```

```{r}
# load empirical data
skidata <- read_csv("/Users/kristian/Documents/Skole/8. Semester/Data Science/Exam/DataScienceSkiDecisionMaking/skidata.csv")

# get avi and terrain into probability space (/n+1)
skidata$Source1 <- skidata$AvalancheConditions / 7  # n is 6
skidata$Source2 <- skidata$TerrainCharacteristics / 5 # n is 4

# get sources within scope for working with log-odds (i.e., avoid 0 and 1)
skidata$Source1 <- ifelse(skidata$Source1 == 0, 0.01, 
                  ifelse(skidata$Source1 == 1, 0.99, skidata$Source1))  # i.e., hardcode 0 to be 0.01 and 1 to be 0.99

skidata$Source2 <- ifelse(skidata$Source2 == 0, 0.01, 
                  ifelse(skidata$Source2 == 1, 0.99, skidata$Source2))  # i.e., hardcode 0 to be 0.01 and 1 to be 0.99

```


```{r}
# pivot data wider
sim_wide_ski <- skidata %>% 
  group_by(id) %>% 
  subset(select = c(id, outcome, Source1, Source2)) %>%
  mutate(row = row_number()) %>% 
  pivot_wider(names_from = id, values_from = c(outcome, Source1, Source2))

# Create the data
dataSimpleBayesSki <- list(
  N = nrow(skidata),
  S = unique(skidata$id),
  outcome = as.matrix(sim_wide_ski[,2:3]),
  Source1 = as.matrix(sim_wide_ski[,4:5]),
  Source2 = as.matrix(sim_wide_ski[,6:7])
)

dataSimpleBayesSkiDre <- sim_wide_ski %>% 
  subset(select = c(outcome_2, Source1_2, Source2_2)) %>% 
  na.omit()

dataSimpleBayesSkiDre <- list(
  N = nrow(dataSimpleBayesSkiDre),
  S = 1,
  outcome = as.matrix(dataSimpleBayesSkiDre[,1]),
  Source1 = as.matrix(dataSimpleBayesSkiDre[,2]),
  Source2 = as.matrix(dataSimpleBayesSkiDre[,3])
)

# feed R the stan model
file <- file.path("simplebayesML.stan")
mod_simpleBayesSki <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
#for (i in seq(2)){
 #  df_temp <- dataSimpleBayesSki %>% 
  #  keep(i == S)
   
# create samples from the model
samples_simple_skiDre <- mod_simpleBayesSki$sample(
  data = dataSimpleBayesSkiDre,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1500,
  iter_sampling = 3000,
  refresh = 500
)


#  temp <- as_draws_df(samples_simple_ski$draws())
 # temp <- temp %>% 
  #  mutate(id = i)
  

  #if (exists("draws_df_emp")) { draws_df_emp <- rbind(draws_df_emp, temp)} 
  #else{draws_df_emp <- temp} 

#}

# get the resulting data frame
draws_df_ski_Dre <- as_draws_df(samples_simple_skiDre$draws())
```


```{r}
# Johan
dataSimpleBayesSkiJoe <- sim_wide_ski %>% 
  subset(select = c(outcome_1, Source1_1, Source2_1)) %>% 
  na.omit()

dataSimpleBayesSkiJoe <- list(
  N = nrow(dataSimpleBayesSkiJoe),
  S = 1,
  outcome = as.matrix(dataSimpleBayesSkiJoe[,1]),
  Source1 = as.matrix(dataSimpleBayesSkiJoe[,2]),
  Source2 = as.matrix(dataSimpleBayesSkiJoe[,3])
)


# feed R the stan model
file <- file.path("simplebayesML.stan")
mod_simpleBayesSki <- cmdstan_model(file, cpp_options = list(stan_threads = TRUE),
                     stanc_options = list("O1"))
#for (i in seq(2)){
 #  df_temp <- dataSimpleBayesSki %>% 
  #  keep(i == S)
   
# create samples from the model
samples_simple_skiJoe <- mod_simpleBayesSki$sample(
  data = dataSimpleBayesSkiJoe,
  seed = 123,
  chains = 2,
  parallel_chains = 2,
  threads_per_chain = 2,
  iter_warmup = 1500,
  iter_sampling = 3000,
  refresh = 500
)


#  temp <- as_draws_df(samples_simple_ski$draws())
 # temp <- temp %>% 
  #  mutate(id = i)
  

  #if (exists("draws_df_emp")) { draws_df_emp <- rbind(draws_df_emp, temp)} 
  #else{draws_df_emp <- temp} 

#}

# get the resulting data frame
draws_df_ski_Joe <- as_draws_df(samples_simple_skiJoe$draws())
```


```{r}
# basic evaluation
samples_simple_skiJoe$cmdstan_diagnose()
samples_simple_skiDre$cmdstan_diagnose()

# diagnostics
summaryJoe <- samples_simple_skiJoe$summary()
samples_simple_skiJoe$loo()

summaryDre <- samples_simple_skiDre$summary()
samples_simple_skiDre$loo()


```

```{r}
# chains mixing plot
p1Joe <- ggplot(draws_df_ski_Joe, aes(.iteration, `bias[1]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p1Dre <- ggplot(draws_df_ski_Dre, aes(.iteration, `bias[1]`, group = .chain, color = .chain)) +
  geom_line(alpha = 0.5) +
  theme_classic()
p1Joe
p1Dre
```

```{r}
# bias plot
Dre <- ggplot(draws_df_ski_Dre) +
  geom_density(aes(`bias_posterior[1]`), alpha = 0.6, fill = "lightblue") +
    annotate("text", colour = "lightblue", x = 0.01, y = 46, label = "Posterior Distribution Bias" , hjust = 0)+
  geom_density(aes(`bias_prior[1]`), alpha = 0.6, fill = "pink") +
    annotate("text", colour = "pink", x = 0.01, y = 43, label = "Prior Distribution Bias", hjust =0)+
  xlab("Bias")+
  ylab("Estimate Densitites")+
  theme_bw()+
  geom_vline(xintercept = 0.77, linetype = "dashed", size = 1.5) +
    annotate("text", x = 0.01, y = 40,  label="Simulated Bias", hjust = 0)+
  geom_vline(xintercept = summaryDre$q5[35], size = 0.5)+
  geom_vline(xintercept = summaryDre$q95[35], size = 0.5)+
  geom_rect(aes(xmin = 0, xmax = 0.3, ymin = 38, ymax = 48), 
            fill = "white", color = "black", alpha = 0)


# bias plot
Joe <- ggplot(draws_df_ski_Joe) +
  geom_density(aes(`bias_posterior[1]`), alpha = 0.6, fill = "lightblue") +
    annotate("text", colour = "lightblue", x = 0.01, y = 46, label = "Posterior Distribution Bias" , hjust = 0)+
  geom_density(aes(`bias_prior[1]`), alpha = 0.6, fill = "pink") +
    annotate("text", colour = "pink", x = 0.01, y = 43, label = "Prior Distribution Bias", hjust =0)+
  xlab("Bias")+
  ylab("Estimate Densitites")+
  theme_bw()+
  geom_vline(xintercept = 0.77, linetype = "dashed", size = 1.5) +
    annotate("text", x = 0.01, y = 40,  label="Simulated Bias", hjust = 0)+
  geom_vline(xintercept = summaryJoe$q5[23], size = 0.5)+
  geom_vline(xintercept = summaryJoe$q95[23], size = 0.5)+
  geom_rect(aes(xmin = 0, xmax = 0.3, ymin = 38, ymax = 48), 
            fill = "white", color = "black", alpha = 0)

Dre+Joe

```



